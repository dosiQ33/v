{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADER - –ó–∞–≥—Ä—É–∑–∫–∞ CSV –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Parquet\n",
    "–≠—Ç–æ—Ç notebook –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ Parquet –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "# %% –ò–ú–ü–û–†–¢–´\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"–ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞–Ω–Ω—ã—Ö: data\n"
     ]
    }
   ],
   "source": [
    "# %% –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–£–¢–ï–ô\n",
    "class DataConfig:\n",
    "    # CSV —Ñ–∞–π–ª—ã (–∏—Å—Ç–æ—á–Ω–∏–∫–∏)\n",
    "    TRAIN_CSV = \"CLTV_UL_TRAIN_MART.csv\"\n",
    "    PROD_CSV = \"CLTV_UL_PROD_SNAPSHOT.csv\"\n",
    "    # CHURN_CSV = \"../churn_result_msb.csv\"\n",
    "    \n",
    "    # Parquet —Ñ–∞–π–ª—ã (—Ü–µ–ª–µ–≤—ã–µ)\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    TRAIN_PARQUET = DATA_DIR / \"train_data.parquet\"\n",
    "    PROD_PARQUET = DATA_DIR / \"prod_data.parquet\"\n",
    "    # CHURN_PARQUET = DATA_DIR / \"churn_data.parquet\"\n",
    "    \n",
    "    @classmethod\n",
    "    def ensure_directories(cls):\n",
    "        cls.DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DataConfig.ensure_directories()\n",
    "print(f\"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞–Ω–Ω—ã—Ö: {DataConfig.DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% –§–£–ù–ö–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò CSV\n",
    "def load_csv_file(file_path, description=\"–§–∞–π–ª\"):\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ {description}: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # –ü–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '|' –∏ –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π windows-1251\n",
    "        df = pd.read_csv(file_path, sep='|', encoding=\"windows-1251\", thousands=',')\n",
    "        print(f\"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ (—Ñ–æ—Ä–º–∞—Ç: sep='|', encoding='windows-1251')\")\n",
    "        return df\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            # –ü–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ','\n",
    "            df = pd.read_csv(file_path, sep=',')\n",
    "            print(f\"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ (—Ñ–æ—Ä–º–∞—Ç: sep=',')\")\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            try:\n",
    "                # –ü–æ–ø—ã—Ç–∫–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '\\t'\n",
    "                df = pd.read_csv(file_path, sep='\\t')\n",
    "                print(f\"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ (—Ñ–æ—Ä–º–∞—Ç: sep='\\\\t')\")\n",
    "                return df\n",
    "            except Exception as e3:\n",
    "                print(f\"   ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e3}\")\n",
    "                return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "–ó–ê–ì–†–£–ó–ö–ê –û–ë–£–ß–ê–Æ–©–ò–• –î–ê–ù–ù–´–•\n",
      "======================================================================\n",
      "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ: CLTV_UL_TRAIN_MART.csv\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ (—Ñ–æ—Ä–º–∞—Ç: sep='|', encoding='windows-1251')\n",
      "\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
      "   –ó–∞–ø–∏—Å–µ–π: 4,052,063\n",
      "   –°—Ç–æ–ª–±—Ü–æ–≤: 23\n",
      "   –ö–ª–∏–µ–Ω—Ç–æ–≤: 233,474\n",
      "   –°–µ–≥–º–µ–Ω—Ç—ã: [1022, 1023, 1026, 1027, 1028, 1040]\n",
      "\n",
      "   –°—Ç–æ–ª–±—Ü—ã: ['CLIENT_ID', 'MONTH_END', 'SEGMENT_ID', 'QUALITY_CODE', 'SUBJECT_KIND_ID', 'EC_SECTOR_ID', 'MARGIN', 'MARGIN_LAG1', 'MARGIN_LAG2', 'MARGIN_LAG3', 'MARGIN_AVG_1M_LAG', 'MARGIN_AVG_2M_LAG', 'MARGIN_AVG_3M_LAG', 'MARGIN_AVG_6M_LAG', 'MARGIN_AVG_12M_LAG', 'MARGIN_STDDEV_12M_LAG', 'MARGIN_GROWTH_RATE_3M', 'MONTH_OF_YEAR', 'QUARTER_OF_YEAR', 'TENURE_MONTHS', 'SEGMENT_AVG_MARGIN', 'SEGMENT_MEDIAN_MARGIN', 'TARGET_NEXT_MARGIN']\n",
      "\n",
      "‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\n",
      "MARGIN_LAG1               34354\n",
      "MARGIN_LAG2               72983\n",
      "MARGIN_LAG3              115858\n",
      "MARGIN_AVG_1M_LAG         34354\n",
      "MARGIN_AVG_2M_LAG         34354\n",
      "MARGIN_AVG_3M_LAG         34354\n",
      "MARGIN_AVG_6M_LAG         34354\n",
      "MARGIN_AVG_12M_LAG        34354\n",
      "MARGIN_STDDEV_12M_LAG     34354\n",
      "MARGIN_GROWTH_RATE_3M    115865\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %% –ó–ê–ì–†–£–ó–ö–ê TRAIN DATA\n",
    "print(\"=\"*70)\n",
    "print(\"–ó–ê–ì–†–£–ó–ö–ê –û–ë–£–ß–ê–Æ–©–ò–• –î–ê–ù–ù–´–•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = load_csv_file(DataConfig.TRAIN_CSV, \"–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ\")\n",
    "\n",
    "if not train_df.empty:\n",
    "    print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   –ó–∞–ø–∏—Å–µ–π: {len(train_df):,}\")\n",
    "    print(f\"   –°—Ç–æ–ª–±—Ü–æ–≤: {len(train_df.columns)}\")\n",
    "    print(f\"   –ö–ª–∏–µ–Ω—Ç–æ–≤: {train_df['CLIENT_ID'].nunique():,}\")\n",
    "    print(f\"   –°–µ–≥–º–µ–Ω—Ç—ã: {sorted(train_df['SEGMENT_ID'].unique())}\")\n",
    "    print(f\"\\n   –°—Ç–æ–ª–±—Ü—ã: {list(train_df.columns)}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "    missing = train_df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\")\n",
    "        print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "–ó–ê–ì–†–£–ó–ö–ê –ü–†–û–î–ê–ö–®–ù –î–ê–ù–ù–´–•\n",
      "======================================================================\n",
      "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –ü—Ä–æ–¥–∞–∫—à–Ω –¥–∞–Ω–Ω—ã–µ: CLTV_UL_PROD_SNAPSHOT.csv\n",
      "   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ (—Ñ–æ—Ä–º–∞—Ç: sep='|', encoding='windows-1251')\n",
      "\n",
      "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
      "   –ó–∞–ø–∏—Å–µ–π: 358,787\n",
      "   –°—Ç–æ–ª–±—Ü–æ–≤: 23\n",
      "   –ö–ª–∏–µ–Ω—Ç–æ–≤: 358,787\n",
      "   –°–µ–≥–º–µ–Ω—Ç—ã: [1022, 1023, 1026, 1027, 1040]\n",
      "\n",
      "   –°—Ç–æ–ª–±—Ü—ã: ['CLIENT_ID', 'MONTH_END', 'SEGMENT_ID', 'QUALITY_CODE', 'SUBJECT_KIND_ID', 'EC_SECTOR_ID', 'MARGIN', 'MARGIN_LAG1', 'MARGIN_LAG2', 'MARGIN_LAG3', 'MARGIN_AVG_1M_LAG', 'MARGIN_AVG_2M_LAG', 'MARGIN_AVG_3M_LAG', 'MARGIN_AVG_6M_LAG', 'MARGIN_AVG_12M_LAG', 'MARGIN_STDDEV_12M_LAG', 'MARGIN_GROWTH_RATE_3M', 'MONTH_OF_YEAR', 'QUARTER_OF_YEAR', 'TENURE_MONTHS', 'SEGMENT_AVG_MARGIN', 'SEGMENT_MEDIAN_MARGIN', 'FORECAST_START_DATE']\n"
     ]
    }
   ],
   "source": [
    "# %% –ó–ê–ì–†–£–ó–ö–ê PROD DATA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–ó–ê–ì–†–£–ó–ö–ê –ü–†–û–î–ê–ö–®–ù –î–ê–ù–ù–´–•\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "prod_df = load_csv_file(DataConfig.PROD_CSV, \"–ü—Ä–æ–¥–∞–∫—à–Ω –¥–∞–Ω–Ω—ã–µ\")\n",
    "\n",
    "if not prod_df.empty:\n",
    "    print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   –ó–∞–ø–∏—Å–µ–π: {len(prod_df):,}\")\n",
    "    print(f\"   –°—Ç–æ–ª–±—Ü–æ–≤: {len(prod_df.columns)}\")\n",
    "    if 'CLIENT_ID' in prod_df.columns:\n",
    "        print(f\"   –ö–ª–∏–µ–Ω—Ç–æ–≤: {prod_df['CLIENT_ID'].nunique():,}\")\n",
    "    if 'SEGMENT_ID' in prod_df.columns:\n",
    "        print(f\"   –°–µ–≥–º–µ–Ω—Ç—ã: {sorted(prod_df['SEGMENT_ID'].unique())}\")\n",
    "    print(f\"\\n   –°—Ç–æ–ª–±—Ü—ã: {list(prod_df.columns)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –ü—Ä–æ–¥–∞–∫—à–Ω –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %% –ó–ê–ì–†–£–ó–ö–ê CHURN DATA\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"–ó–ê–ì–†–£–ó–ö–ê CHURN –î–ê–ù–ù–´–•\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# churn_df = load_csv_file(DataConfig.CHURN_CSV, \"Churn –¥–∞–Ω–Ω—ã–µ\")\n",
    "\n",
    "# if not churn_df.empty:\n",
    "#     print(f\"\\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "#     print(f\"   –ó–∞–ø–∏—Å–µ–π: {len(churn_df):,}\")\n",
    "#     print(f\"   –°—Ç–æ–ª–±—Ü–æ–≤: {len(churn_df.columns)}\")\n",
    "#     print(f\"\\n   –°—Ç–æ–ª–±—Ü—ã: {list(churn_df.columns)}\")\n",
    "    \n",
    "#     # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "#     if 'churn_probability' in churn_df.columns:\n",
    "#         churn_df = churn_df.rename(columns={'churn_probability': 'CHURN_PROB_3M'})\n",
    "#         print(\"   ‚úì –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω —Å—Ç–æ–ª–±–µ—Ü 'churn_probability' ‚Üí 'CHURN_PROB_3M'\")\n",
    "    \n",
    "#     churn_df.columns = churn_df.columns.str.upper()\n",
    "#     print(f\"   ‚úì –°—Ç–æ–ª–±—Ü—ã –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è  Churn –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "–°–û–•–†–ê–ù–ï–ù–ò–ï –í PARQUET\n",
      "======================================================================\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\train_data.parquet\n",
      "   ‚úì –†–∞–∑–º–µ—Ä: 349.20 MB\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∫—à–Ω –¥–∞–Ω–Ω—ã—Ö...\n",
      "   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data\\prod_data.parquet\n",
      "   ‚úì –†–∞–∑–º–µ—Ä: 25.86 MB\n",
      "\n",
      "======================================================================\n",
      "‚úÖ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\n",
      "======================================================================\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: 2 –∏–∑ 3\n",
      "–ì–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: train, prod\n",
      "\n",
      "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º notebook –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑:\n",
      "  - data\\train_data.parquet\n",
      "  - data\\prod_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# %% –°–û–•–†–ê–ù–ï–ù–ò–ï –í PARQUET\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–°–û–•–†–ê–ù–ï–ù–ò–ï –í PARQUET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "saved_files = []\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ train\n",
    "if not train_df.empty:\n",
    "    print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    train_df.to_parquet(DataConfig.TRAIN_PARQUET, index=False, compression='snappy')\n",
    "    file_size = os.path.getsize(DataConfig.TRAIN_PARQUET) / (1024 * 1024)  # MB\n",
    "    print(f\"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {DataConfig.TRAIN_PARQUET}\")\n",
    "    print(f\"   ‚úì –†–∞–∑–º–µ—Ä: {file_size:.2f} MB\")\n",
    "    saved_files.append('train')\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ prod\n",
    "if not prod_df.empty:\n",
    "    print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∫—à–Ω –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    prod_df.to_parquet(DataConfig.PROD_PARQUET, index=False, compression='snappy')\n",
    "    file_size = os.path.getsize(DataConfig.PROD_PARQUET) / (1024 * 1024)  # MB\n",
    "    print(f\"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {DataConfig.PROD_PARQUET}\")\n",
    "    print(f\"   ‚úì –†–∞–∑–º–µ—Ä: {file_size:.2f} MB\")\n",
    "    saved_files.append('prod')\n",
    "\n",
    "# # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ churn\n",
    "# if not churn_df.empty:\n",
    "#     print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ churn –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "#     churn_df.to_parquet(DataConfig.CHURN_PARQUET, index=False, compression='snappy')\n",
    "#     file_size = os.path.getsize(DataConfig.CHURN_PARQUET) / (1024 * 1024)  # MB\n",
    "#     print(f\"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {DataConfig.CHURN_PARQUET}\")\n",
    "#     print(f\"   ‚úì –†–∞–∑–º–µ—Ä: {file_size:.2f} MB\")\n",
    "#     saved_files.append('churn')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(saved_files)} –∏–∑ 3\")\n",
    "print(f\"–ì–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: {', '.join(saved_files)}\")\n",
    "print(f\"\\n–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º notebook –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑:\")\n",
    "print(f\"  - {DataConfig.TRAIN_PARQUET}\")\n",
    "print(f\"  - {DataConfig.PROD_PARQUET}\")\n",
    "# print(f\"  - {DataConfig.CHURN_PARQUET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "–¢–ï–°–¢: –ü–†–û–í–ï–†–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ò–ó PARQUET\n",
      "======================================================================\n",
      "\n",
      "‚úì Train –∑–∞–≥—Ä—É–∂–µ–Ω: 4,052,063 –∑–∞–ø–∏—Å–µ–π\n",
      "  –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n",
      "   CLIENT_ID                MONTH_END  SEGMENT_ID QUALITY_CODE  \\\n",
      "0       1049  2024-01-31 00:00:00.000        1023           –ë–ì   \n",
      "1       1049  2024-02-29 00:00:00.000        1023           –ë–ì   \n",
      "2       1049  2024-03-31 00:00:00.000        1023           –ë–ì   \n",
      "3       1049  2024-04-30 00:00:00.000        1023           –ë–ì   \n",
      "4       1049  2024-05-31 00:00:00.000        1023           –ë–ì   \n",
      "\n",
      "  SUBJECT_KIND_ID  EC_SECTOR_ID        MARGIN   MARGIN_LAG1   MARGIN_LAG2  \\\n",
      "0              –Æ–õ          1041  3.849652e+06  2.622380e+07  1.052012e+06   \n",
      "1              –Æ–õ          1041  2.758478e+06  3.849652e+06  2.622380e+07   \n",
      "2              –Æ–õ          1041  3.380613e+06  2.758478e+06  3.849652e+06   \n",
      "3              –Æ–õ          1041  2.407339e+06  3.380613e+06  2.758478e+06   \n",
      "4              –Æ–õ          1041  1.204042e+06  2.407339e+06  3.380613e+06   \n",
      "\n",
      "    MARGIN_LAG3  ...  MARGIN_AVG_6M_LAG  MARGIN_AVG_12M_LAG  \\\n",
      "0  1.371855e+06  ...       6.307584e+06        3.888274e+06   \n",
      "1  1.052012e+06  ...       6.840623e+06        3.922258e+06   \n",
      "2  2.622380e+07  ...       7.051160e+06        4.014342e+06   \n",
      "3  3.849652e+06  ...       7.452912e+06        4.176133e+06   \n",
      "4  2.758478e+06  ...       7.723977e+06        4.331034e+06   \n",
      "\n",
      "   MARGIN_STDDEV_12M_LAG  MARGIN_GROWTH_RATE_3M  MONTH_OF_YEAR  \\\n",
      "0           7.441387e+06               8.599425              1   \n",
      "1           7.440169e+06               9.923461              2   \n",
      "2           7.416766e+06              -0.653996              3   \n",
      "3           7.378165e+06              -0.704145              4   \n",
      "4           7.315587e+06              -0.735565              5   \n",
      "\n",
      "   QUARTER_OF_YEAR  TENURE_MONTHS  SEGMENT_AVG_MARGIN  SEGMENT_MEDIAN_MARGIN  \\\n",
      "0                1             13        1.776851e+06            69179.01980   \n",
      "1                1             14        2.381317e+06            56740.10795   \n",
      "2                1             15        2.305359e+06            55395.61970   \n",
      "3                2             16        2.415292e+06            51905.25370   \n",
      "4                2             17        3.132953e+06            55029.70115   \n",
      "\n",
      "   TARGET_NEXT_MARGIN  \n",
      "0        2.758478e+06  \n",
      "1        3.380613e+06  \n",
      "2        2.407339e+06  \n",
      "3        1.204042e+06  \n",
      "4        2.326329e+06  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "‚úì Prod –∑–∞–≥—Ä—É–∂–µ–Ω: 358,787 –∑–∞–ø–∏—Å–µ–π\n",
      "\n",
      "======================================================================\n",
      "‚úÖ –í–°–ï –§–ê–ô–õ–´ –ì–û–¢–û–í–´ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %% –ü–†–û–í–ï–†–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ò–ó PARQUET (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–¢–ï–°–¢: –ü–†–û–í–ï–†–ö–ê –ó–ê–ì–†–£–ó–ö–ò –ò–ó PARQUET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if DataConfig.TRAIN_PARQUET.exists():\n",
    "    test_train = pd.read_parquet(DataConfig.TRAIN_PARQUET)\n",
    "    print(f\"\\n‚úì Train –∑–∞–≥—Ä—É–∂–µ–Ω: {len(test_train):,} –∑–∞–ø–∏—Å–µ–π\")\n",
    "    print(f\"  –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "    print(test_train.head())\n",
    "\n",
    "if DataConfig.PROD_PARQUET.exists():\n",
    "    test_prod = pd.read_parquet(DataConfig.PROD_PARQUET)\n",
    "    print(f\"\\n‚úì Prod –∑–∞–≥—Ä—É–∂–µ–Ω: {len(test_prod):,} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "# if DataConfig.CHURN_PARQUET.exists():\n",
    "#     test_churn = pd.read_parquet(DataConfig.CHURN_PARQUET)\n",
    "#     print(f\"\\n‚úì Churn –∑–∞–≥—Ä—É–∂–µ–Ω: {len(test_churn):,} –∑–∞–ø–∏—Å–µ–π\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ –í–°–ï –§–ê–ô–õ–´ –ì–û–¢–û–í–´ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
