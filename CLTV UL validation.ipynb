{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ИМПОРТ БИБЛИОТЕК\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict, deque\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Настройка отображения pandas\n",
    "pd.set_option(\"display.float_format\", \"{:,.2f}\".format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Подавление предупреждений\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка визуализации\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "logger.info(\"Библиотеки успешно загружены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# КОНФИГУРАЦИЯ ПАРАМЕТРОВ\n# ============================================================================\n\nclass ModelConfig:\n    \n    # Пути к данным\n    DATA_DIR = Path(\"data\")\n    TRAIN_PATH = DATA_DIR / \"train_data.parquet\"\n    \n    # Директория для моделей\n    MODEL_DIR = Path(\"models\")\n    MODEL_VERSION = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    # Временные границы разделения данных\n    TRAIN_CUTOFF = \"2025-01-31\"       # Конец обучающей выборки\n    VALIDATION_CUTOFF = \"2025-03-31\"  # Конец валидационной выборки\n    # OOT (Out-of-Time) тестовая выборка: после VALIDATION_CUTOFF\n    \n    # Прогнозирование\n    FORECAST_START = \"2025-10-31\"\n    HORIZON_MONTHS = 6\n    MIN_SAMPLES_PER_SEGMENT = 1000\n    \n    # Признаки модели\n    CATEGORICAL_FEATURES = [\n        'QUALITY_CODE',     \n        'SUBJECT_KIND_ID',   \n        'EC_SECTOR_ID',      # Используем как категориальную фичу вместо разделения по сегментам\n        'SEGMENT_ID'         # Оставляем SEGMENT_ID как категориальную фичу\n    ]\n    \n    BASE_FEATURES = [\n        # Текущие и лаговые значения маржи\n        'MARGIN', 'MARGIN_LAG1', 'MARGIN_LAG2', 'MARGIN_LAG3',\n        # Скользящие средние\n        'MARGIN_AVG_1M_LAG', 'MARGIN_AVG_2M_LAG', 'MARGIN_AVG_3M_LAG',\n        'MARGIN_AVG_6M_LAG', 'MARGIN_AVG_12M_LAG',\n        # Волатильность и тренд\n        'MARGIN_STDDEV_12M_LAG', 'MARGIN_GROWTH_RATE_3M',\n        # Временные признаки\n        'MONTH_OF_YEAR', 'QUARTER_OF_YEAR', 'TENURE_MONTHS'\n    ]\n    \n    # Гиперпараметры CatBoost\n    CATBOOST_PARAMS = {\n        'iterations': 1600,           \n        'depth': 4,                  \n        'learning_rate': 0.05,        \n        'l2_leaf_reg': 3,             \n        'random_seed': 42,           \n        'loss_function': 'RMSE',     \n        'verbose': 100,               \n        'early_stopping_rounds': 50   \n    }\n    \n    @classmethod\n    def ensure_directories(cls):\n        cls.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n        (cls.MODEL_DIR / cls.MODEL_VERSION).mkdir(parents=True, exist_ok=True)\n\n# Инициализация конфигурации\nModelConfig.ensure_directories()\n\nlogger.info(f\"Версия модели: {ModelConfig.MODEL_VERSION}\")\nlogger.info(f\"Обучающая выборка: до {ModelConfig.TRAIN_CUTOFF}\")\nlogger.info(f\"Валидационная выборка: {ModelConfig.TRAIN_CUTOFF} - {ModelConfig.VALIDATION_CUTOFF}\")\nlogger.info(f\"OOT тестовая выборка: после {ModelConfig.VALIDATION_CUTOFF}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
    "# ============================================================================\n",
    "\n",
    "def load_parquet_data(file_path: Path) -> pd.DataFrame:\n",
    "    if not file_path.exists():\n",
    "        logger.warning(f\"Файл не найден: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        logger.info(f\"Загружено {len(df):,} записей из {file_path.name}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка загрузки {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def preprocess_categorical_features(df: pd.DataFrame, \n",
    "                                   categorical_cols: list) -> pd.DataFrame:\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # Заполнение пропусков\n",
    "            df_processed[col] = df_processed[col].fillna('UNKNOWN')\n",
    "            # Приведение к строке\n",
    "            df_processed[col] = df_processed[col].astype(str)\n",
    "            # Удаление .0 из строковых представлений чисел\n",
    "            df_processed[col] = df_processed[col].str.replace('.0', '', regex=False)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "\n",
    "def transform_target(y: pd.Series) -> pd.Series:\n",
    "    return np.sign(y) * np.log1p(np.abs(y))\n",
    "\n",
    "\n",
    "logger.info(\"Вспомогательные функции загружены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Начало загрузки данных...\")\n",
    "\n",
    "# Загрузка данных из Parquet\n",
    "df_train = load_parquet_data(ModelConfig.TRAIN_PATH)\n",
    "\n",
    "# Проверка успешности загрузки\n",
    "if df_train.empty:\n",
    "    logger.error(\"Ошибка: данные не загружены!\")\n",
    "    logger.info(\"Надо прогнать 'data_loader.ipynb'\")\n",
    "else:\n",
    "    logger.info(f\"Обучающая выборка: {len(df_train):,} записей\")\n",
    "    logger.info(f\"Уникальных клиентов: {df_train['CLIENT_ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPLORATORY DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Начало разведочного анализа данных...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ОБЩАЯ ИНФОРМАЦИЯ О ДАННЫХ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Размер данных: {df_train.shape[0]:,} строк x {df_train.shape[1]} столбцов\")\n",
    "print(f\"Период данных: {df_train['MONTH_END'].min()} - {df_train['MONTH_END'].max()}\")\n",
    "print(f\"Уникальных клиентов: {df_train['CLIENT_ID'].nunique():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ\")\n",
    "print(\"=\"*80)\n",
    "missing = df_train.isnull().sum()\n",
    "missing_pct = 100 * missing / len(df_train)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Столбец': missing.index,\n",
    "    'Пропусков': missing.values,\n",
    "    'Процент': missing_pct.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Пропусков'] > 0].sort_values('Пропусков', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Пропущенных значений не обнаружено\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РАСПРЕДЕЛЕНИЕ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ (TARGET_NEXT_MARGIN)\")\n",
    "print(\"=\"*80)\n",
    "target_stats = df_train['TARGET_NEXT_MARGIN'].describe()\n",
    "print(target_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РАСПРЕДЕЛЕНИЕ ПО СЕГМЕНТАМ\")\n",
    "print(\"=\"*80)\n",
    "segment_counts = df_train['SEGMENT_ID'].value_counts()\n",
    "for segment, count in segment_counts.items():\n",
    "    pct = 100 * count / len(df_train)\n",
    "    print(f\"{segment}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СТАТИСТИКА МАРЖИ ПО СЕГМЕНТАМ\")\n",
    "print(\"=\"*80)\n",
    "margin_by_segment = df_train.groupby('SEGMENT_ID')['TARGET_NEXT_MARGIN'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('median', 'median'),\n",
    "    ('std', 'std'),\n",
    "    ('min', 'min'),\n",
    "    ('max', 'max')\n",
    "])\n",
    "print(margin_by_segment)\n",
    "\n",
    "# Визуализация распределения целевой переменной\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Гистограмма\n",
    "axes[0].hist(df_train['TARGET_NEXT_MARGIN'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('TARGET_NEXT_MARGIN')\n",
    "axes[0].set_ylabel('Частота')\n",
    "axes[0].set_title('Распределение целевой переменной')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot по сегментам\n",
    "df_train.boxplot(column='TARGET_NEXT_MARGIN', by='SEGMENT_ID', ax=axes[1])\n",
    "axes[1].set_xlabel('Сегмент')\n",
    "axes[1].set_ylabel('TARGET_NEXT_MARGIN')\n",
    "axes[1].set_title('Распределение маржи по сегментам')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ПРОВЕРКА ДАННЫХ\n# ============================================================================\n\nlogger.info(\"Проверка загруженных данных...\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ИНФОРМАЦИЯ О СЕГМЕНТАХ\")\nprint(\"=\"*80)\nprint(df_train['SEGMENT_ID'].value_counts().sort_index())\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ИНФОРМАЦИЯ О EC_SECTOR_ID (BUS_SECTOR_ID)\")\nprint(\"=\"*80)\nprint(df_train['EC_SECTOR_ID'].value_counts().sort_index())\n\n# Детальная статистика\nprint(\"\\n\" + \"=\"*80)\nprint(\"ОБЩАЯ СТАТИСТИКА\")\nprint(\"=\"*80)\n\nn_records = len(df_train)\nn_clients = df_train['CLIENT_ID'].nunique()\navg_margin = df_train['TARGET_NEXT_MARGIN'].mean()\n\nprint(f\"\\nВсего данных:\")\nprint(f\"  Записей: {n_records:>12,}\")\nprint(f\"  Клиентов: {n_clients:>11,}\")\nprint(f\"  Средняя маржа: {avg_margin:>12,.2f}\")\n\nprint(f\"\\nСегменты (SEGMENT_ID):\")\nfor segment_id in sorted(df_train['SEGMENT_ID'].unique()):\n    segment_data = df_train[df_train['SEGMENT_ID'] == segment_id]\n    n_seg_records = len(segment_data)\n    n_seg_clients = segment_data['CLIENT_ID'].nunique()\n    pct_records = 100 * n_seg_records / n_records\n    \n    print(f\"  {segment_id}: {n_seg_records:,} записей ({pct_records:.1f}%), {n_seg_clients:,} клиентов\")\n\nprint(f\"\\nБизнес-секторы (EC_SECTOR_ID):\")\nfor sector_id in sorted(df_train['EC_SECTOR_ID'].unique()):\n    sector_data = df_train[df_train['EC_SECTOR_ID'] == sector_id]\n    n_sec_records = len(sector_data)\n    pct_records = 100 * n_sec_records / n_records\n    \n    print(f\"  {sector_id}: {n_sec_records:,} записей ({pct_records:.1f}%)\")\n\nlogger.info(\"Проверка данных завершена\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ФОРМИРОВАНИЕ ПРИЗНАКОВОГО ПРОСТРАНСТВА\n# ============================================================================\n\nlogger.info(\"Подготовка признаков...\")\n\n# Предобработка категориальных признаков\ndf_train_processed = preprocess_categorical_features(\n    df_train, ModelConfig.CATEGORICAL_FEATURES\n)\n\n# Полный список признаков (базовые + категориальные)\nall_features = ModelConfig.BASE_FEATURES + ModelConfig.CATEGORICAL_FEATURES\n\n# Фильтрация доступных признаков\navailable_features = [\n    feature for feature in all_features \n    if feature in df_train_processed.columns\n]\n\n# Заполнение пропусков в числовых признаках\nnumeric_features = [\n    feature for feature in available_features \n    if feature not in ModelConfig.CATEGORICAL_FEATURES\n]\n\nfor feature in numeric_features:\n    df_train_processed[feature] = df_train_processed[feature].fillna(0.0)\n\nlogger.info(f\"Всего признаков: {len(available_features)}\")\nlogger.info(f\"  Числовые: {len(numeric_features)}\")\nlogger.info(f\"  Категориальные: {len(ModelConfig.CATEGORICAL_FEATURES)}\")\n\nprint(f\"\\nСписок признаков модели:\")\nprint(f\"  Всего: {len(available_features)}\")\nprint(f\"  Числовые ({len(numeric_features)}): {', '.join(numeric_features[:5])}...\")\nprint(f\"  Категориальные ({len(ModelConfig.CATEGORICAL_FEATURES)}): {', '.join(ModelConfig.CATEGORICAL_FEATURES)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# КЛАСС ЕДИНОЙ МОДЕЛИ CLTV (БЕЗ СЕГМЕНТАЦИИ)\n# ============================================================================\n\nclass CLTVModel:\n    \"\"\"\n    Единая модель CLTV для всех клиентов сегмента SMALL.\n    Использует EC_SECTOR_ID и SEGMENT_ID как категориальные признаки вместо разделения.\n    \"\"\"\n    \n    def __init__(self, model_params: dict):\n        self.model = None\n        self.metrics = {}\n        self.feature_importance = None\n        self.model_params = model_params\n        \n    def train(\n        self,\n        X_train: pd.DataFrame,\n        y_train: pd.Series,\n        X_val: pd.DataFrame,\n        y_val: pd.Series,\n        X_test: pd.DataFrame,\n        y_test: pd.Series,\n        categorical_features: list = None\n    ) -> dict:\n        \"\"\"\n        Обучение единой модели на всех данных.\n        \"\"\"\n        logger.info(f\"\\nОбучение единой модели CLTV\")\n        logger.info(f\"  Train: {len(X_train):,} записей\")\n        logger.info(f\"  Validation: {len(X_val):,} записей\")\n        logger.info(f\"  OOT Test: {len(X_test):,} записей\")\n        \n        # Определение индексов категориальных признаков\n        categorical_indices = []\n        if categorical_features:\n            feature_names = X_train.columns.tolist()\n            categorical_indices = [\n                feature_names.index(feature) \n                for feature in categorical_features \n                if feature in feature_names\n            ]\n            logger.info(f\"  Категориальные признаки: {categorical_features}\")\n        \n        # Создание Pool объектов для CatBoost\n        train_pool = Pool(X_train, y_train, cat_features=categorical_indices)\n        val_pool = Pool(X_val, y_val, cat_features=categorical_indices)\n        test_pool = Pool(X_test, y_test, cat_features=categorical_indices)\n        \n        # Обучение модели\n        self.model = CatBoostRegressor(**self.model_params)\n        self.model.fit(\n            train_pool, \n            eval_set=val_pool, \n            use_best_model=True\n        )\n        \n        # Расчет метрик на всех выборках\n        predictions = {\n            'train': self.model.predict(X_train),\n            'val': self.model.predict(X_val),\n            'test': self.model.predict(X_test)\n        }\n        \n        self.metrics = {\n            # Обучающая выборка\n            'train_r2': r2_score(y_train, predictions['train']),\n            'train_rmse': np.sqrt(mean_squared_error(y_train, predictions['train'])),\n            'train_mae': mean_absolute_error(y_train, predictions['train']),\n            'train_samples': len(X_train),\n            # Валидационная выборка\n            'val_r2': r2_score(y_val, predictions['val']),\n            'val_rmse': np.sqrt(mean_squared_error(y_val, predictions['val'])),\n            'val_mae': mean_absolute_error(y_val, predictions['val']),\n            'val_samples': len(X_val),\n            # OOT тестовая выборка\n            'test_r2': r2_score(y_test, predictions['test']),\n            'test_rmse': np.sqrt(mean_squared_error(y_test, predictions['test'])),\n            'test_mae': mean_absolute_error(y_test, predictions['test']),\n            'test_samples': len(X_test),\n        }\n        \n        # Feature importance\n        self.feature_importance = pd.DataFrame({\n            'feature': X_train.columns,\n            'importance': self.model.feature_importances_\n        }).sort_values('importance', ascending=False)\n        \n        # Вывод результатов\n        logger.info(\"Результаты обучения:\")\n        logger.info(f\"  Train R²: {self.metrics['train_r2']:.4f}\")\n        logger.info(f\"  Val R²:   {self.metrics['val_r2']:.4f}\")\n        logger.info(f\"  Test R²:  {self.metrics['test_r2']:.4f} (OOT)\")\n        \n        return self.metrics\n    \n    def predict(self, X: pd.DataFrame) -> np.ndarray:\n        \"\"\"\n        Предсказание на новых данных.\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"Модель не обучена. Вызовите метод train() сначала.\")\n        \n        return self.model.predict(X)\n\n\nlogger.info(\"Класс CLTVModel определен\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ПОДГОТОВКА ОБУЧАЮЩИХ ДАННЫХ\n# Разделение на Train / Validation / OOT Test\n# ============================================================================\n\nlogger.info(\"Формирование обучающих выборок...\")\n\n# Стабилизирующая трансформация целевой переменной\ndf_train_processed['target_transformed'] = transform_target(\n    df_train_processed['TARGET_NEXT_MARGIN']\n)\n\n# Временное разделение данных\ntrain_end_date = pd.to_datetime(ModelConfig.TRAIN_CUTOFF)\nval_end_date = pd.to_datetime(ModelConfig.VALIDATION_CUTOFF)\n\nmonth_end_dates = pd.to_datetime(df_train_processed['MONTH_END'])\n\ntrain_mask = month_end_dates <= train_end_date\nval_mask = (month_end_dates > train_end_date) & (month_end_dates <= val_end_date)\ntest_mask = month_end_dates > val_end_date\n\n# Статистика разделения\nprint(\"\\n\" + \"=\"*80)\nprint(\"РАЗДЕЛЕНИЕ ДАННЫХ\")\nprint(\"=\"*80)\nprint(f\"Train:      {train_mask.sum():>10,} записей ({100*train_mask.sum()/len(df_train_processed):>5.1f}%)\")\nprint(f\"Validation: {val_mask.sum():>10,} записей ({100*val_mask.sum()/len(df_train_processed):>5.1f}%)\")\nprint(f\"OOT Test:   {test_mask.sum():>10,} записей ({100*test_mask.sum()/len(df_train_processed):>5.1f}%)\")\n\n# Подготовка единого датасета (без разделения по сегментам)\nX_train = df_train_processed.loc[train_mask, available_features]\ny_train = df_train_processed.loc[train_mask, 'target_transformed']\n\nX_val = df_train_processed.loc[val_mask, available_features]\ny_val = df_train_processed.loc[val_mask, 'target_transformed']\n\nX_test = df_train_processed.loc[test_mask, available_features]\ny_test = df_train_processed.loc[test_mask, 'target_transformed']\n\nprint(f\"\\n{'='*80}\")\nprint(\"РАЗМЕРЫ ВЫБОРОК\")\nprint(f\"{'='*80}\")\nprint(f\"X_train: {X_train.shape}\")\nprint(f\"X_val:   {X_val.shape}\")\nprint(f\"X_test:  {X_test.shape}\")\n\nlogger.info(\"Данные подготовлены для обучения единой модели\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ОБУЧЕНИЕ МОДЕЛИ\n# ============================================================================\n\nlogger.info(\"\\nНачало обучения модели...\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ОБУЧЕНИЕ ЕДИНОЙ МОДЕЛИ CLTV\")\nprint(\"=\"*80)\n\n# Инициализация модели\ncltv_model = CLTVModel(model_params=ModelConfig.CATBOOST_PARAMS)\n\n# Обучение модели\nmetrics = cltv_model.train(\n    X_train=X_train,\n    y_train=y_train,\n    X_val=X_val,\n    y_val=y_val,\n    X_test=X_test,\n    y_test=y_test,\n    categorical_features=ModelConfig.CATEGORICAL_FEATURES\n)\n\n# Вывод топ-20 важных признаков\nprint(f\"\\n{'='*80}\")\nprint(\"ТОП-20 ВАЖНЫХ ПРИЗНАКОВ\")\nprint(f\"{'='*80}\")\nfor idx, row in cltv_model.feature_importance.head(20).iterrows():\n    print(f\"  {row['feature']:30s}: {row['importance']:6.2f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ОБУЧЕНИЕ ЗАВЕРШЕНО\")\nprint(\"=\"*80)\n\nlogger.info(\"Модель успешно обучена\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# СВОДКА РЕЗУЛЬТАТОВ\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ИТОГОВЫЕ МЕТРИКИ КАЧЕСТВА МОДЕЛИ\")\nprint(\"=\"*80)\n\n# Формирование таблицы метрик\nsummary_data = {\n    'Метрика': ['R²', 'RMSE', 'MAE', 'Количество'],\n    'Train': [\n        f\"{metrics['train_r2']:.4f}\",\n        f\"{metrics['train_rmse']:.2f}\",\n        f\"{metrics['train_mae']:.2f}\",\n        f\"{metrics['train_samples']:,}\"\n    ],\n    'Validation': [\n        f\"{metrics['val_r2']:.4f}\",\n        f\"{metrics['val_rmse']:.2f}\",\n        f\"{metrics['val_mae']:.2f}\",\n        f\"{metrics['val_samples']:,}\"\n    ],\n    'Test (OOT)': [\n        f\"{metrics['test_r2']:.4f}\",\n        f\"{metrics['test_rmse']:.2f}\",\n        f\"{metrics['test_mae']:.2f}\",\n        f\"{metrics['test_samples']:,}\"\n    ]\n}\n\nsummary_df = pd.DataFrame(summary_data)\nprint(\"\\n\" + summary_df.to_string(index=False))\n\nprint(f\"\\n{'='*80}\")\nprint(\"ФИНАЛЬНЫЕ МЕТРИКИ\")\nprint(f\"{'='*80}\")\nprint(f\"  Test R² (OOT): {metrics['test_r2']:.4f}  <- Основная метрика качества\")\nprint(f\"  Test RMSE:     {metrics['test_rmse']:.2f}\")\nprint(f\"  Test MAE:      {metrics['test_mae']:.2f}\")\nprint(f\"{'='*80}\")\n\n# Анализ стабильности модели\ntrain_val_diff = abs(metrics['train_r2'] - metrics['val_r2'])\nval_test_diff = abs(metrics['val_r2'] - metrics['test_r2'])\n\nprint(f\"\\nАНАЛИЗ СТАБИЛЬНОСТИ МОДЕЛИ:\")\nprint(f\"{'='*80}\")\nprint(f\"  |Train R² - Val R²|:  {train_val_diff:.4f}\")\nprint(f\"  |Val R² - Test R²|:   {val_test_diff:.4f}\")\n\nif val_test_diff < 0.05:\n    status = \"✓ Стабильная модель\"\nelif val_test_diff < 0.10:\n    status = \"⚠ Умеренная деградация\"\nelse:\n    status = \"✗ Сильная деградация\"\n\nprint(f\"  Статус: {status}\")\n\nlogger.info(f\"Финальная OOT R²: {metrics['test_r2']:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# СОХРАНЕНИЕ МОДЕЛИ И АРТЕФАКТОВ\n# ============================================================================\n\nlogger.info(\"Сохранение результатов...\")\n\nsave_dir = ModelConfig.MODEL_DIR / ModelConfig.MODEL_VERSION\n\n# Сохранение модели CatBoost\nmodel_path = save_dir / \"cltv_model_small.cbm\"\ncltv_model.model.save_model(str(model_path))\nlogger.info(f\"Сохранена модель: {model_path.name}\")\n\n# Сохранение сводки метрик\nmetrics_path = save_dir / \"model_metrics.csv\"\nsummary_df.to_csv(metrics_path, index=False)\nlogger.info(f\"Сохранены метрики: {metrics_path.name}\")\n\n# Сохранение feature importance\nimportance_path = save_dir / \"feature_importance.csv\"\ncltv_model.feature_importance.to_csv(importance_path, index=False)\nlogger.info(f\"Сохранена важность признаков: {importance_path.name}\")\n\n# Сохранение метаданных\nmetadata = {\n    'model_version': ModelConfig.MODEL_VERSION,\n    'training_date': datetime.now().isoformat(),\n    'model_type': 'single_model',\n    'target_segment': 'small (1026, 1027)',\n    'features': available_features,\n    'categorical_features': ModelConfig.CATEGORICAL_FEATURES,\n    'model_parameters': ModelConfig.CATBOOST_PARAMS,\n    'data_split': {\n        'train_cutoff': ModelConfig.TRAIN_CUTOFF,\n        'validation_cutoff': ModelConfig.VALIDATION_CUTOFF,\n        'train_size': int(metrics['train_samples']),\n        'val_size': int(metrics['val_samples']),\n        'test_size': int(metrics['test_samples'])\n    },\n    'performance_metrics': {\n        k: float(v) if isinstance(v, (int, float, np.number)) else v\n        for k, v in metrics.items()\n    }\n}\n\nmetadata_path = save_dir / \"model_metadata.json\"\nwith open(metadata_path, 'w', encoding='utf-8') as f:\n    json.dump(metadata, f, indent=2, ensure_ascii=False)\nlogger.info(f\"Сохранены метаданные: {metadata_path.name}\")\n\n# Сохранение объекта модели\nmodel_object_path = save_dir / \"cltv_model_object.pkl\"\nwith open(model_object_path, 'wb') as f:\n    pickle.dump(cltv_model, f)\nlogger.info(f\"Сохранен объект модели: {model_object_path.name}\")\n\nprint(f\"\\n{'='*80}\")\nprint(f\"РЕЗУЛЬТАТЫ СОХРАНЕНЫ\")\nprint(f\"{'='*80}\")\nprint(f\"Директория: {save_dir}\")\nprint(f\"\\nСохраненные файлы:\")\nprint(f\"  - Модель CatBoost: cltv_model_small.cbm\")\nprint(f\"  - Метрики: model_metrics.csv\")\nprint(f\"  - Feature importance: feature_importance.csv\")\nprint(f\"  - Метаданные: model_metadata.json\")\nprint(f\"  - Объект модели: cltv_model_object.pkl\")\nprint(f\"{'='*80}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\n# ============================================================================\n\nlogger.info(\"Создание визуализаций...\")\n\n# График 1: Сравнение R² на разных выборках\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# График 1: Столбчатая диаграмма метрик\ndatasets = ['Train', 'Validation', 'OOT Test']\nr2_values = [metrics['train_r2'], metrics['val_r2'], metrics['test_r2']]\ncolors = ['#3498db', '#2ecc71', '#e74c3c']\n\nbars = axes[0].bar(datasets, r2_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\naxes[0].set_ylabel('R² (коэффициент детерминации)', fontsize=12, fontweight='bold')\naxes[0].set_title('Качество модели на разных выборках', fontsize=14, fontweight='bold', pad=15)\naxes[0].grid(axis='y', alpha=0.3, linestyle='--')\naxes[0].axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, linewidth=1, label='Порог 0.8')\naxes[0].legend()\n\n# Добавление значений на столбцы\nfor bar, value in zip(bars, r2_values):\n    height = bar.get_height()\n    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n                f'{value:.4f}',\n                ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# График 2: Топ-15 важных признаков\ntop_features = cltv_model.feature_importance.head(15)\naxes[1].barh(range(len(top_features)), top_features['importance'].values, \n             color='#9b59b6', alpha=0.8, edgecolor='black', linewidth=1)\naxes[1].set_yticks(range(len(top_features)))\naxes[1].set_yticklabels(top_features['feature'].values)\naxes[1].set_xlabel('Важность признака', fontsize=12, fontweight='bold')\naxes[1].set_title('Топ-15 важных признаков', fontsize=14, fontweight='bold', pad=15)\naxes[1].invert_yaxis()\naxes[1].grid(axis='x', alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplot_path = save_dir / 'model_performance.png'\nplt.savefig(plot_path, dpi=150, bbox_inches='tight')\nlogger.info(f\"Сохранен график: {plot_path.name}\")\nplt.show()\n\n# График 3: Детальный анализ категориальных признаков\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# EC_SECTOR_ID распределение\nsector_counts = df_train_processed['EC_SECTOR_ID'].value_counts()\naxes[0, 0].bar(range(len(sector_counts)), sector_counts.values, \n               color='#3498db', alpha=0.7, edgecolor='black')\naxes[0, 0].set_xticks(range(len(sector_counts)))\naxes[0, 0].set_xticklabels(sector_counts.index, rotation=45, ha='right')\naxes[0, 0].set_ylabel('Количество записей', fontweight='bold')\naxes[0, 0].set_title('Распределение по EC_SECTOR_ID', fontweight='bold', pad=10)\naxes[0, 0].grid(axis='y', alpha=0.3)\n\n# SEGMENT_ID распределение\nsegment_counts = df_train_processed['SEGMENT_ID'].value_counts()\naxes[0, 1].bar(range(len(segment_counts)), segment_counts.values, \n               color='#2ecc71', alpha=0.7, edgecolor='black')\naxes[0, 1].set_xticks(range(len(segment_counts)))\naxes[0, 1].set_xticklabels(segment_counts.index, rotation=45, ha='right')\naxes[0, 1].set_ylabel('Количество записей', fontweight='bold')\naxes[0, 1].set_title('Распределение по SEGMENT_ID', fontweight='bold', pad=10)\naxes[0, 1].grid(axis='y', alpha=0.3)\n\n# QUALITY_CODE распределение\nquality_counts = df_train_processed['QUALITY_CODE'].value_counts()\naxes[1, 0].bar(range(len(quality_counts)), quality_counts.values, \n               color='#e74c3c', alpha=0.7, edgecolor='black')\naxes[1, 0].set_xticks(range(len(quality_counts)))\naxes[1, 0].set_xticklabels(quality_counts.index, rotation=45, ha='right')\naxes[1, 0].set_ylabel('Количество записей', fontweight='bold')\naxes[1, 0].set_title('Распределение по QUALITY_CODE', fontweight='bold', pad=10)\naxes[1, 0].grid(axis='y', alpha=0.3)\n\n# SUBJECT_KIND_ID распределение\nsubject_counts = df_train_processed['SUBJECT_KIND_ID'].value_counts()\naxes[1, 1].bar(range(len(subject_counts)), subject_counts.values, \n               color='#f39c12', alpha=0.7, edgecolor='black')\naxes[1, 1].set_xticks(range(len(subject_counts)))\naxes[1, 1].set_xticklabels(subject_counts.index, rotation=45, ha='right')\naxes[1, 1].set_ylabel('Количество записей', fontweight='bold')\naxes[1, 1].set_title('Распределение по SUBJECT_KIND_ID', fontweight='bold', pad=10)\naxes[1, 1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\ncategorical_plot_path = save_dir / 'categorical_features_distribution.png'\nplt.savefig(categorical_plot_path, dpi=150, bbox_inches='tight')\nlogger.info(f\"Сохранен график: {categorical_plot_path.name}\")\nplt.show()\n\nprint(f\"\\nВизуализации сохранены:\")\nprint(f\"  - {plot_path}\")\nprint(f\"  - {categorical_plot_path}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}