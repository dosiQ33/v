{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ИМПОРТ БИБЛИОТЕК\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict, deque\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Настройка отображения pandas\n",
    "pd.set_option(\"display.float_format\", \"{:,.2f}\".format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Подавление предупреждений\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка визуализации\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "logger.info(\"Библиотеки успешно загружены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# КОНФИГУРАЦИЯ ПАРАМЕТРОВ\n",
    "# ============================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \n",
    "    # Пути к данным\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    TRAIN_PATH = DATA_DIR / \"train_data.parquet\"\n",
    "    \n",
    "    # Директория для моделей\n",
    "    MODEL_DIR = Path(\"models\")\n",
    "    MODEL_VERSION = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Временные границы разделения данных\n",
    "    TRAIN_CUTOFF = \"2025-01-31\"       # Конец обучающей выборки\n",
    "    VALIDATION_CUTOFF = \"2025-03-31\"  # Конец валидационной выборки\n",
    "    # OOT (Out-of-Time) тестовая выборка: после VALIDATION_CUTOFF\n",
    "    \n",
    "    # Прогнозирование\n",
    "    FORECAST_START = \"2025-10-31\"\n",
    "    HORIZON_MONTHS = 6\n",
    "    MIN_SAMPLES_PER_SEGMENT = 1000\n",
    "    \n",
    "    # Признаки модели\n",
    "    CATEGORICAL_FEATURES = [\n",
    "        'QUALITY_CODE',     \n",
    "        'SUBJECT_KIND_ID',   \n",
    "        'EC_SECTOR_ID'       \n",
    "    ]\n",
    "    \n",
    "    BASE_FEATURES = [\n",
    "        # Текущие и лаговые значения маржи\n",
    "        'MARGIN', 'MARGIN_LAG1', 'MARGIN_LAG2', 'MARGIN_LAG3',\n",
    "        # Скользящие средние\n",
    "        'MARGIN_AVG_1M_LAG', 'MARGIN_AVG_2M_LAG', 'MARGIN_AVG_3M_LAG',\n",
    "        'MARGIN_AVG_6M_LAG', 'MARGIN_AVG_12M_LAG',\n",
    "        # Волатильность и тренд\n",
    "        'MARGIN_STDDEV_12M_LAG', 'MARGIN_GROWTH_RATE_3M',\n",
    "        # Временные признаки\n",
    "        'MONTH_OF_YEAR', 'QUARTER_OF_YEAR', 'TENURE_MONTHS'\n",
    "    ]\n",
    "    \n",
    "    # Маппинг сегментов клиентов\n",
    "    SEGMENT_MAPPING = {\n",
    "        '1026': 'small',              # МИКРО бизнес\n",
    "        '1027': 'small',              # МАЛЫЙ бизнес\n",
    "        '1022': 'large_and_middle',   # СРЕДНИЙ бизнес\n",
    "        '1023': 'large_and_middle',   # КРУПНЫЙ бизнес\n",
    "        '1040': 'large_and_middle',   # Прочие крупные\n",
    "    }\n",
    "    \n",
    "    # Гиперпараметры CatBoost\n",
    "    CATBOOST_PARAMS = {\n",
    "        'iterations': 1600,           \n",
    "        'depth': 4,                  \n",
    "        'learning_rate': 0.05,        \n",
    "        'l2_leaf_reg': 3,             \n",
    "        'random_seed': 42,           \n",
    "        'loss_function': 'RMSE',     \n",
    "        'verbose': 100,               \n",
    "        'early_stopping_rounds': 50   \n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def ensure_directories(cls):\n",
    "        cls.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        (cls.MODEL_DIR / cls.MODEL_VERSION).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Инициализация конфигурации\n",
    "ModelConfig.ensure_directories()\n",
    "\n",
    "logger.info(f\"Версия модели: {ModelConfig.MODEL_VERSION}\")\n",
    "logger.info(f\"Обучающая выборка: до {ModelConfig.TRAIN_CUTOFF}\")\n",
    "logger.info(f\"Валидационная выборка: {ModelConfig.TRAIN_CUTOFF} - {ModelConfig.VALIDATION_CUTOFF}\")\n",
    "logger.info(f\"OOT тестовая выборка: после {ModelConfig.VALIDATION_CUTOFF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
    "# ============================================================================\n",
    "\n",
    "def load_parquet_data(file_path: Path) -> pd.DataFrame:\n",
    "    if not file_path.exists():\n",
    "        logger.warning(f\"Файл не найден: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        logger.info(f\"Загружено {len(df):,} записей из {file_path.name}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка загрузки {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def preprocess_categorical_features(df: pd.DataFrame, \n",
    "                                   categorical_cols: list) -> pd.DataFrame:\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # Заполнение пропусков\n",
    "            df_processed[col] = df_processed[col].fillna('UNKNOWN')\n",
    "            # Приведение к строке\n",
    "            df_processed[col] = df_processed[col].astype(str)\n",
    "            # Удаление .0 из строковых представлений чисел\n",
    "            df_processed[col] = df_processed[col].str.replace('.0', '', regex=False)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "\n",
    "def transform_target(y: pd.Series) -> pd.Series:\n",
    "    return np.sign(y) * np.log1p(np.abs(y))\n",
    "\n",
    "\n",
    "logger.info(\"Вспомогательные функции загружены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Начало загрузки данных...\")\n",
    "\n",
    "# Загрузка данных из Parquet\n",
    "df_train = load_parquet_data(ModelConfig.TRAIN_PATH)\n",
    "\n",
    "# Проверка успешности загрузки\n",
    "if df_train.empty:\n",
    "    logger.error(\"Ошибка: данные не загружены!\")\n",
    "    logger.info(\"Надо прогнать 'data_loader.ipynb'\")\n",
    "else:\n",
    "    logger.info(f\"Обучающая выборка: {len(df_train):,} записей\")\n",
    "    logger.info(f\"Уникальных клиентов: {df_train['CLIENT_ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPLORATORY DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Начало разведочного анализа данных...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ОБЩАЯ ИНФОРМАЦИЯ О ДАННЫХ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Размер данных: {df_train.shape[0]:,} строк x {df_train.shape[1]} столбцов\")\n",
    "print(f\"Период данных: {df_train['MONTH_END'].min()} - {df_train['MONTH_END'].max()}\")\n",
    "print(f\"Уникальных клиентов: {df_train['CLIENT_ID'].nunique():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ\")\n",
    "print(\"=\"*80)\n",
    "missing = df_train.isnull().sum()\n",
    "missing_pct = 100 * missing / len(df_train)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Столбец': missing.index,\n",
    "    'Пропусков': missing.values,\n",
    "    'Процент': missing_pct.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Пропусков'] > 0].sort_values('Пропусков', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Пропущенных значений не обнаружено\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РАСПРЕДЕЛЕНИЕ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ (TARGET_NEXT_MARGIN)\")\n",
    "print(\"=\"*80)\n",
    "target_stats = df_train['TARGET_NEXT_MARGIN'].describe()\n",
    "print(target_stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РАСПРЕДЕЛЕНИЕ ПО СЕГМЕНТАМ\")\n",
    "print(\"=\"*80)\n",
    "segment_counts = df_train['SEGMENT_ID'].value_counts()\n",
    "for segment, count in segment_counts.items():\n",
    "    pct = 100 * count / len(df_train)\n",
    "    print(f\"{segment}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СТАТИСТИКА МАРЖИ ПО СЕГМЕНТАМ\")\n",
    "print(\"=\"*80)\n",
    "margin_by_segment = df_train.groupby('SEGMENT_ID')['TARGET_NEXT_MARGIN'].agg([\n",
    "    ('count', 'count'),\n",
    "    ('mean', 'mean'),\n",
    "    ('median', 'median'),\n",
    "    ('std', 'std'),\n",
    "    ('min', 'min'),\n",
    "    ('max', 'max')\n",
    "])\n",
    "print(margin_by_segment)\n",
    "\n",
    "# Визуализация распределения целевой переменной\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Гистограмма\n",
    "axes[0].hist(df_train['TARGET_NEXT_MARGIN'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('TARGET_NEXT_MARGIN')\n",
    "axes[0].set_ylabel('Частота')\n",
    "axes[0].set_title('Распределение целевой переменной')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot по сегментам\n",
    "df_train.boxplot(column='TARGET_NEXT_MARGIN', by='SEGMENT_ID', ax=axes[1])\n",
    "axes[1].set_xlabel('Сегмент')\n",
    "axes[1].set_ylabel('TARGET_NEXT_MARGIN')\n",
    "axes[1].set_title('Распределение маржи по сегментам')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# АГРЕГАЦИЯ СЕГМЕНТОВ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Применение маппинга сегментов...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ИСХОДНАЯ СЕГМЕНТАЦИЯ КЛИЕНТОВ\")\n",
    "print(\"=\"*80)\n",
    "print(df_train['SEGMENT_ID'].value_counts().sort_index())\n",
    "\n",
    "# Применение маппинга сегментов\n",
    "df_train['SEGMENT_ID'] = (\n",
    "    df_train['SEGMENT_ID']\n",
    "    .astype(str)\n",
    "    .map(ModelConfig.SEGMENT_MAPPING)\n",
    ")\n",
    "\n",
    "# Удаление строк с неизвестными сегментами\n",
    "rows_before = len(df_train)\n",
    "df_train = df_train.dropna(subset=['SEGMENT_ID'])\n",
    "rows_after = len(df_train)\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "if rows_removed > 0:\n",
    "    logger.info(f\"Удалено {rows_removed:,} записей с неизвестными сегментами\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"УКРУПНЕННАЯ СЕГМЕНТАЦИЯ (2 СЕГМЕНТА)\")\n",
    "print(\"=\"*80)\n",
    "print(df_train['SEGMENT_ID'].value_counts().sort_index())\n",
    "\n",
    "# Детальная статистика по сегментам\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"СТАТИСТИКА ПО СЕГМЕНТАМ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for segment_name in sorted(df_train['SEGMENT_ID'].unique()):\n",
    "    segment_data = df_train[df_train['SEGMENT_ID'] == segment_name]\n",
    "    \n",
    "    n_records = len(segment_data)\n",
    "    n_clients = segment_data['CLIENT_ID'].nunique()\n",
    "    pct_records = 100 * n_records / len(df_train)\n",
    "    avg_margin = segment_data['TARGET_NEXT_MARGIN'].mean()\n",
    "    \n",
    "    print(f\"\\n{segment_name.upper()}:\")\n",
    "    print(f\"  Записей: {n_records:>12,} ({pct_records:>5.1f}%)\")\n",
    "    print(f\"  Клиентов: {n_clients:>11,}\")\n",
    "\n",
    "logger.info(\"Сегментация применена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ФОРМИРОВАНИЕ ПРИЗНАКОВОГО ПРОСТРАНСТВА\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Подготовка признаков...\")\n",
    "\n",
    "# Все категориальные признаки (включая SEGMENT_ID)\n",
    "all_categorical_features = ModelConfig.CATEGORICAL_FEATURES + ['SEGMENT_ID']\n",
    "\n",
    "# Предобработка категориальных признаков\n",
    "df_train_processed = preprocess_categorical_features(\n",
    "    df_train, all_categorical_features\n",
    ")\n",
    "\n",
    "# Полный список признаков\n",
    "all_features = (\n",
    "    ['SEGMENT_ID'] + \n",
    "    ModelConfig.BASE_FEATURES + \n",
    "    ModelConfig.CATEGORICAL_FEATURES\n",
    ")\n",
    "\n",
    "# Фильтрация доступных признаков\n",
    "available_features = [\n",
    "    feature for feature in all_features \n",
    "    if feature in df_train_processed.columns\n",
    "]\n",
    "\n",
    "# Заполнение пропусков в числовых признаках\n",
    "numeric_features = [\n",
    "    feature for feature in available_features \n",
    "    if feature not in all_categorical_features\n",
    "]\n",
    "\n",
    "for feature in numeric_features:\n",
    "    df_train_processed[feature] = df_train_processed[feature].fillna(0.0)\n",
    "\n",
    "logger.info(f\"Всего признаков: {len(available_features)}\")\n",
    "logger.info(f\"  Числовые: {len(numeric_features)}\")\n",
    "logger.info(f\"  Категориальные: {len(ModelConfig.CATEGORICAL_FEATURES)}\")\n",
    "\n",
    "print(f\"\\nСписок признаков модели:\")\n",
    "print(f\"  Сегментация: SEGMENT_ID\")\n",
    "print(f\"  Числовые: {', '.join(numeric_features[:5])}...\")\n",
    "print(f\"  Категориальные: {', '.join(ModelConfig.CATEGORICAL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# КЛАСС СЕГМЕНТИРОВАННОЙ МОДЕЛИ CLTV\n",
    "# ============================================================================\n",
    "\n",
    "class SegmentedCLTVModel:\n",
    "    \n",
    "    def __init__(self, model_params: dict):\n",
    "        self.models = {}\n",
    "        self.metrics = {}\n",
    "        self.feature_importance = {}\n",
    "        self.model_params = model_params\n",
    "        \n",
    "    def train_segment_model(\n",
    "        self,\n",
    "        segment_id: str,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: pd.Series,\n",
    "        X_val: pd.DataFrame,\n",
    "        y_val: pd.Series,\n",
    "        X_test: pd.DataFrame,\n",
    "        y_test: pd.Series,\n",
    "        categorical_features: list = None\n",
    "    ) -> tuple:\n",
    "        logger.info(f\"\\nОбучение сегмента: {segment_id}\")\n",
    "        logger.info(f\"  Train: {len(X_train):,} записей\")\n",
    "        logger.info(f\"  Validation: {len(X_val):,} записей\")\n",
    "        logger.info(f\"  OOT Test: {len(X_test):,} записей\")\n",
    "        \n",
    "        # Определение индексов категориальных признаков\n",
    "        categorical_indices = []\n",
    "        if categorical_features:\n",
    "            feature_names = X_train.columns.tolist()\n",
    "            categorical_indices = [\n",
    "                feature_names.index(feature) \n",
    "                for feature in categorical_features \n",
    "                if feature in feature_names\n",
    "            ]\n",
    "        \n",
    "        # Создание Pool объектов для CatBoost\n",
    "        train_pool = Pool(X_train, y_train, cat_features=categorical_indices)\n",
    "        val_pool = Pool(X_val, y_val, cat_features=categorical_indices)\n",
    "        test_pool = Pool(X_test, y_test, cat_features=categorical_indices)\n",
    "        \n",
    "        # Обучение модели\n",
    "        model = CatBoostRegressor(**self.model_params)\n",
    "        model.fit(\n",
    "            train_pool, \n",
    "            eval_set=val_pool, \n",
    "            use_best_model=True\n",
    "        )\n",
    "        \n",
    "        # Расчет метрик на всех выборках\n",
    "        predictions = {\n",
    "            'train': model.predict(X_train),\n",
    "            'val': model.predict(X_val),\n",
    "            'test': model.predict(X_test)\n",
    "        }\n",
    "        \n",
    "        metrics = {\n",
    "            # Обучающая выборка\n",
    "            'train_r2': r2_score(y_train, predictions['train']),\n",
    "            'train_rmse': np.sqrt(mean_squared_error(y_train, predictions['train'])),\n",
    "            'train_mae': mean_absolute_error(y_train, predictions['train']),\n",
    "            'train_samples': len(X_train),\n",
    "            # Валидационная выборка\n",
    "            'val_r2': r2_score(y_val, predictions['val']),\n",
    "            'val_rmse': np.sqrt(mean_squared_error(y_val, predictions['val'])),\n",
    "            'val_mae': mean_absolute_error(y_val, predictions['val']),\n",
    "            'val_samples': len(X_val),\n",
    "            # OOT тестовая выборка\n",
    "            'test_r2': r2_score(y_test, predictions['test']),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, predictions['test'])),\n",
    "            'test_mae': mean_absolute_error(y_test, predictions['test']),\n",
    "            'test_samples': len(X_test),\n",
    "        }\n",
    "        \n",
    "        # Feature importance\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Вывод результатов\n",
    "        logger.info(\"Результаты обучения:\")\n",
    "        logger.info(f\"  Train R²: {metrics['train_r2']:.4f}\")\n",
    "        logger.info(f\"  Val R²:   {metrics['val_r2']:.4f}\")\n",
    "        logger.info(f\"  Test R²:  {metrics['test_r2']:.4f} (OOT)\")\n",
    "        \n",
    "        # Сохранение результатов\n",
    "        self.models[segment_id] = model\n",
    "        self.metrics[segment_id] = metrics\n",
    "        self.feature_importance[segment_id] = importance_df\n",
    "        \n",
    "        return model, metrics\n",
    "    \n",
    "    def predict(self, segment_id: str, X: pd.DataFrame) -> np.ndarray:\n",
    "        if segment_id not in self.models:\n",
    "            raise ValueError(f\"Модель для сегмента '{segment_id}' не обучена\")\n",
    "        \n",
    "        # Удаление SEGMENT_ID из признаков если присутствует\n",
    "        X_pred = X.drop('SEGMENT_ID', axis=1) if 'SEGMENT_ID' in X.columns else X\n",
    "        \n",
    "        return self.models[segment_id].predict(X_pred)\n",
    "\n",
    "\n",
    "logger.info(\"Класс SegmentedCLTVModel определен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ПОДГОТОВКА ОБУЧАЮЩИХ ДАННЫХ\n",
    "# Разделение на Train / Validation / OOT Test\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Формирование обучающих выборок...\")\n",
    "\n",
    "# Стабилизирующая трансформация целевой переменной\n",
    "df_train_processed['target_transformed'] = transform_target(\n",
    "    df_train_processed['TARGET_NEXT_MARGIN']\n",
    ")\n",
    "\n",
    "# Временное разделение данных\n",
    "train_end_date = pd.to_datetime(ModelConfig.TRAIN_CUTOFF)\n",
    "val_end_date = pd.to_datetime(ModelConfig.VALIDATION_CUTOFF)\n",
    "\n",
    "month_end_dates = pd.to_datetime(df_train_processed['MONTH_END'])\n",
    "\n",
    "train_mask = month_end_dates <= train_end_date\n",
    "val_mask = (month_end_dates > train_end_date) & (month_end_dates <= val_end_date)\n",
    "test_mask = month_end_dates > val_end_date\n",
    "\n",
    "# Статистика разделения\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РАЗДЕЛЕНИЕ ДАННЫХ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train:      {train_mask.sum():>10,} записей ({100*train_mask.sum()/len(df_train_processed):>5.1f}%)\")\n",
    "print(f\"Validation: {val_mask.sum():>10,} записей ({100*val_mask.sum()/len(df_train_processed):>5.1f}%)\")\n",
    "print(f\"OOT Test:   {test_mask.sum():>10,} записей ({100*test_mask.sum()/len(df_train_processed):>5.1f}%)\")\n",
    "\n",
    "# Подготовка данных по сегментам\n",
    "segment_datasets = {}\n",
    "\n",
    "for segment_id in sorted(df_train_processed['SEGMENT_ID'].unique()):\n",
    "    segment_mask = df_train_processed['SEGMENT_ID'] == segment_id\n",
    "    \n",
    "    # Комбинированные маски для каждой выборки\n",
    "    train_segment_mask = segment_mask & train_mask\n",
    "    val_segment_mask = segment_mask & val_mask\n",
    "    test_segment_mask = segment_mask & test_mask\n",
    "    \n",
    "    # Признаки без SEGMENT_ID\n",
    "    model_features = [f for f in available_features if f != 'SEGMENT_ID']\n",
    "    \n",
    "    # Формирование наборов данных\n",
    "    segment_datasets[segment_id] = {\n",
    "        'X_train': df_train_processed.loc[train_segment_mask, model_features],\n",
    "        'y_train': df_train_processed.loc[train_segment_mask, 'target_transformed'],\n",
    "        'X_val': df_train_processed.loc[val_segment_mask, model_features],\n",
    "        'y_val': df_train_processed.loc[val_segment_mask, 'target_transformed'],\n",
    "        'X_test': df_train_processed.loc[test_segment_mask, model_features],\n",
    "        'y_test': df_train_processed.loc[test_segment_mask, 'target_transformed']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{segment_id.upper()}:\")\n",
    "    print(f\"  Train: {len(segment_datasets[segment_id]['X_train']):>10,} записей\")\n",
    "    print(f\"  Val:   {len(segment_datasets[segment_id]['X_val']):>10,} записей\")\n",
    "    print(f\"  Test:  {len(segment_datasets[segment_id]['X_test']):>10,} записей\")\n",
    "\n",
    "logger.info(\"Данные подготовлены для обучения\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ОБУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"\\nНачало обучения моделей...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ОБУЧЕНИЕ СЕГМЕНТИРОВАННЫХ МОДЕЛЕЙ CLTV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Инициализация модели\n",
    "cltv_model = SegmentedCLTVModel(model_params=ModelConfig.CATBOOST_PARAMS)\n",
    "\n",
    "# Обучение моделей для каждого сегмента\n",
    "for segment_id in sorted(segment_datasets.keys()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"СЕГМЕНТ: {segment_id.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    dataset = segment_datasets[segment_id]\n",
    "    \n",
    "    model, metrics = cltv_model.train_segment_model(\n",
    "        segment_id=segment_id,\n",
    "        X_train=dataset['X_train'],\n",
    "        y_train=dataset['y_train'],\n",
    "        X_val=dataset['X_val'],\n",
    "        y_val=dataset['y_val'],\n",
    "        X_test=dataset['X_test'],\n",
    "        y_test=dataset['y_test'],\n",
    "        categorical_features=ModelConfig.CATEGORICAL_FEATURES\n",
    "    )\n",
    "    \n",
    "    # Вывод топ-10 важных признаков\n",
    "    print(f\"\\nТоп-10 важных признаков:\")\n",
    "    importance_df = cltv_model.feature_importance[segment_id]\n",
    "    for idx, row in importance_df.head(10).iterrows():\n",
    "        print(f\"  {row['feature']:30s}: {row['importance']:6.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ОБУЧЕНИЕ ЗАВЕРШЕНО\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "logger.info(\"Все модели успешно обучены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# СВОДКА РЕЗУЛЬТАТОВ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ИТОГОВЫЕ МЕТРИКИ КАЧЕСТВА МОДЕЛЕЙ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Формирование сводной таблицы\n",
    "summary_records = []\n",
    "\n",
    "for segment_id, metrics in cltv_model.metrics.items():\n",
    "    summary_records.append({\n",
    "        'Сегмент': segment_id,\n",
    "        'Train_R²': f\"{metrics['train_r2']:.4f}\",\n",
    "        'Val_R²': f\"{metrics['val_r2']:.4f}\",\n",
    "        'Test_R²': f\"{metrics['test_r2']:.4f}\",\n",
    "        'Train_RMSE': f\"{metrics['train_rmse']:.2f}\",\n",
    "        'Val_RMSE': f\"{metrics['val_rmse']:.2f}\",\n",
    "        'Test_RMSE': f\"{metrics['test_rmse']:.2f}\",\n",
    "        'Train_MAE': f\"{metrics['train_mae']:.2f}\",\n",
    "        'Val_MAE': f\"{metrics['val_mae']:.2f}\",\n",
    "        'Test_MAE': f\"{metrics['test_mae']:.2f}\",\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_records)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Расчет средних метрик\n",
    "avg_metrics = {\n",
    "    'train_r2': np.mean([m['train_r2'] for m in cltv_model.metrics.values()]),\n",
    "    'val_r2': np.mean([m['val_r2'] for m in cltv_model.metrics.values()]),\n",
    "    'test_r2': np.mean([m['test_r2'] for m in cltv_model.metrics.values()]),\n",
    "    'test_rmse': np.mean([m['test_rmse'] for m in cltv_model.metrics.values()]),\n",
    "    'test_mae': np.mean([m['test_mae'] for m in cltv_model.metrics.values()]),\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"СРЕДНИЕ МЕТРИКИ ПО ВСЕМ СЕГМЕНТАМ\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Train R²:     {avg_metrics['train_r2']:.4f}\")\n",
    "print(f\"  Val R²:       {avg_metrics['val_r2']:.4f}\")\n",
    "print(f\"  Test R² (OOT): {avg_metrics['test_r2']:.4f}  <- Финальная метрика качества\")\n",
    "print(f\"  Test RMSE:    {avg_metrics['test_rmse']:.2f}\")\n",
    "print(f\"  Test MAE:     {avg_metrics['test_mae']:.2f}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Анализ стабильности модели\n",
    "print(f\"\\nАНАЛИЗ СТАБИЛЬНОСТИ МОДЕЛЕЙ:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for segment_id, metrics in cltv_model.metrics.items():\n",
    "    train_val_diff = abs(metrics['train_r2'] - metrics['val_r2'])\n",
    "    val_test_diff = abs(metrics['val_r2'] - metrics['test_r2'])\n",
    "    \n",
    "    print(f\"\\n{segment_id.upper()}:\")\n",
    "    print(f\"  |Train R² - Val R²|:  {train_val_diff:.4f}\")\n",
    "    print(f\"  |Val R² - Test R²|:   {val_test_diff:.4f}\")\n",
    "    \n",
    "    if val_test_diff < 0.05:\n",
    "        status = \"Стабильная модель\"\n",
    "    elif val_test_diff < 0.10:\n",
    "        status = \"Умеренная деградация\"\n",
    "    else:\n",
    "        status = \"Сильная деградация\"\n",
    "    \n",
    "    print(f\"  Статус: {status}\")\n",
    "\n",
    "logger.info(f\"Финальная OOT R²: {avg_metrics['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# СОХРАНЕНИЕ МОДЕЛЕЙ И АРТЕФАКТОВ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Сохранение результатов...\")\n",
    "\n",
    "save_dir = ModelConfig.MODEL_DIR / ModelConfig.MODEL_VERSION\n",
    "\n",
    "# Сохранение моделей CatBoost\n",
    "for segment_id, model in cltv_model.models.items():\n",
    "    model_path = save_dir / f\"cltv_model_{segment_id}.cbm\"\n",
    "    model.save_model(str(model_path))\n",
    "    logger.info(f\"Сохранена модель: {model_path.name}\")\n",
    "\n",
    "# Сохранение сводки метрик\n",
    "metrics_path = save_dir / \"model_metrics.csv\"\n",
    "summary_df.to_csv(metrics_path, index=False)\n",
    "logger.info(f\"Сохранены метрики: {metrics_path.name}\")\n",
    "\n",
    "# Сохранение feature importance\n",
    "for segment_id, importance_df in cltv_model.feature_importance.items():\n",
    "    importance_path = save_dir / f\"feature_importance_{segment_id}.csv\"\n",
    "    importance_df.to_csv(importance_path, index=False)\n",
    "    logger.info(f\"Сохранена важность признаков: {importance_path.name}\")\n",
    "\n",
    "# Сохранение метаданных\n",
    "metadata = {\n",
    "    'model_version': ModelConfig.MODEL_VERSION,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'segments': list(cltv_model.models.keys()),\n",
    "    'features': available_features,\n",
    "    'segment_mapping': ModelConfig.SEGMENT_MAPPING,\n",
    "    'model_parameters': ModelConfig.CATBOOST_PARAMS,\n",
    "    'data_split': {\n",
    "        'train_cutoff': ModelConfig.TRAIN_CUTOFF,\n",
    "        'validation_cutoff': ModelConfig.VALIDATION_CUTOFF,\n",
    "        'train_size': int(train_mask.sum()),\n",
    "        'val_size': int(val_mask.sum()),\n",
    "        'test_size': int(test_mask.sum())\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        seg_id: {\n",
    "            k: float(v) if isinstance(v, (int, float, np.number)) else v\n",
    "            for k, v in metrics.items()\n",
    "        }\n",
    "        for seg_id, metrics in cltv_model.metrics.items()\n",
    "    },\n",
    "    'average_metrics': avg_metrics\n",
    "}\n",
    "\n",
    "metadata_path = save_dir / \"model_metadata.json\"\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "logger.info(f\"Сохранены метаданные: {metadata_path.name}\")\n",
    "\n",
    "# Сохранение объекта модели\n",
    "model_object_path = save_dir / \"cltv_model_object.pkl\"\n",
    "with open(model_object_path, 'wb') as f:\n",
    "    pickle.dump(cltv_model, f)\n",
    "logger.info(f\"Сохранен объект модели: {model_object_path.name}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"РЕЗУЛЬТАТЫ СОХРАНЕНЫ\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Директория: {save_dir}\")\n",
    "print(f\"\\nСохраненные файлы:\")\n",
    "print(f\"  - Модели CatBoost: {len(cltv_model.models)} файлов\")\n",
    "print(f\"  - Метрики: model_metrics.csv\")\n",
    "print(f\"  - Feature importance: {len(cltv_model.models)} файлов\")\n",
    "print(f\"  - Метаданные: model_metadata.json\")\n",
    "print(f\"  - Объект модели: cltv_model_object.pkl\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Создание визуализаций...\")\n",
    "\n",
    "# График сравнения R² на разных выборках\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "segments = list(cltv_model.metrics.keys())\n",
    "x_pos = np.arange(len(segments))\n",
    "bar_width = 0.25\n",
    "\n",
    "r2_train = [cltv_model.metrics[seg]['train_r2'] for seg in segments]\n",
    "r2_val = [cltv_model.metrics[seg]['val_r2'] for seg in segments]\n",
    "r2_test = [cltv_model.metrics[seg]['test_r2'] for seg in segments]\n",
    "\n",
    "bars1 = ax.bar(x_pos - bar_width, r2_train, bar_width, \n",
    "               label='Train R²', alpha=0.8, color='#3498db')\n",
    "bars2 = ax.bar(x_pos, r2_val, bar_width, \n",
    "               label='Validation R²', alpha=0.8, color='#2ecc71')\n",
    "bars3 = ax.bar(x_pos + bar_width, r2_test, bar_width, \n",
    "               label='OOT Test R²', alpha=0.8, color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Сегмент', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('R² (коэффициент детерминации)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Сравнение качества моделей на разных выборках', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([seg.replace('_', ' ').title() for seg in segments])\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Добавление значений на столбцы\n",
    "for i, (t, v, o) in enumerate(zip(r2_train, r2_val, r2_test)):\n",
    "    ax.text(i - bar_width, t + 0.01, f'{t:.3f}', \n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "    ax.text(i, v + 0.01, f'{v:.3f}', \n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "    ax.text(i + bar_width, o + 0.01, f'{o:.3f}', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = save_dir / 'model_performance_comparison.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "logger.info(f\"Сохранен график: {plot_path.name}\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nВизуализация сохранена: {plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
